{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038891,
     "end_time": "2021-05-19T06:51:07.134105",
     "exception": false,
     "start_time": "2021-05-19T06:51:07.095214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:#ff6666' role=\"tab\" aria-controls=\"home\"><center>Narrative Identification on Demonetization Tweets</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037174,
     "end_time": "2021-05-19T06:51:07.209539",
     "exception": false,
     "start_time": "2021-05-19T06:51:07.172365",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:07.291273Z",
     "iopub.status.busy": "2021-05-19T06:51:07.290628Z",
     "iopub.status.idle": "2021-05-19T06:51:07.293173Z",
     "shell.execute_reply": "2021-05-19T06:51:07.293792Z"
    },
    "papermill": {
     "duration": 0.046769,
     "end_time": "2021-05-19T06:51:07.293953",
     "exception": false,
     "start_time": "2021-05-19T06:51:07.247184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword = \"demonetization\" \n",
    "number = 10000\n",
    "filename = \"demonetization-tweets_Clusters.csv\"\n",
    "file_count = \"demonetization-tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:07.373421Z",
     "iopub.status.busy": "2021-05-19T06:51:07.372805Z",
     "iopub.status.idle": "2021-05-19T06:51:09.105432Z",
     "shell.execute_reply": "2021-05-19T06:51:09.104841Z"
    },
    "papermill": {
     "duration": 1.773248,
     "end_time": "2021-05-19T06:51:09.105549",
     "exception": false,
     "start_time": "2021-05-19T06:51:07.332301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize,TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037245,
     "end_time": "2021-05-19T06:51:09.181568",
     "exception": false,
     "start_time": "2021-05-19T06:51:09.144323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:09.268295Z",
     "iopub.status.busy": "2021-05-19T06:51:09.267634Z",
     "iopub.status.idle": "2021-05-19T06:51:30.783173Z",
     "shell.execute_reply": "2021-05-19T06:51:30.783663Z"
    },
    "papermill": {
     "duration": 21.564366,
     "end_time": "2021-05-19T06:51:30.783844",
     "exception": false,
     "start_time": "2021-05-19T06:51:09.219478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the encoding of the data file\n",
    "import chardet\n",
    "with open('../input/demonetizationtweetscsv/demonetization-tweets.csv','rb') as f:\n",
    "    result = chardet.detect(f.read())  \n",
    "result #Windows-1252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037274,
     "end_time": "2021-05-19T06:51:30.859406",
     "exception": false,
     "start_time": "2021-05-19T06:51:30.822132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2: Clean the tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:30.959709Z",
     "iopub.status.busy": "2021-05-19T06:51:30.958948Z",
     "iopub.status.idle": "2021-05-19T06:51:31.848186Z",
     "shell.execute_reply": "2021-05-19T06:51:31.847561Z"
    },
    "papermill": {
     "duration": 0.951177,
     "end_time": "2021-05-19T06:51:31.848304",
     "exception": false,
     "start_time": "2021-05-19T06:51:30.897127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/dtypes/inference.py:178: FutureWarning: Possible nested set at position 1\n",
      "  re.compile(obj)\n"
     ]
    }
   ],
   "source": [
    "# Import the data file\n",
    "df=pd.read_csv('../input/demonetizationtweetscsv/demonetization-tweets.csv',encoding=result['encoding'])\n",
    "df= df.drop(['Unnamed: 0'],axis=1)\n",
    "df=df[0:number]\n",
    "df=df['text']\n",
    "df=pd.DataFrame({'tweet':df})\n",
    "\n",
    "#clean the tweets\n",
    "df['cleaned_tweet']= df['tweet'].replace(r'\\'|\\\"|\\,|\\.|\\?|\\+|\\-|\\/|\\=|\\(|\\)|\\n|\"', '', regex=True)\n",
    "df['cleaned_tweet']=df['cleaned_tweet'].replace(\"  \",\" \")\n",
    "\n",
    "words_remove = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\", \"there\",\"all\",\"we\",\n",
    "                \"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\n",
    "                \"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\"has\",\"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\n",
    "                \"from\",\"com\",\"org\",\"like\",\"likes\",\"so\",\"said\",\"from\",\"what\",\"told\",\"over\",\"more\",\"other\",\n",
    "                \"have\",\"last\",\"with\",\"this\",\"that\",\"such\",\"when\",\"been\",\"says\",\"will\",\"also\",\"where\",\"why\",\n",
    "                \"would\",\"today\", \"in\", \"on\", \"you\", \"r\", \"d\", \"u\", \"hw\",\"wat\", \"oly\", \"s\", \"b\", \"ht\", \n",
    "                \"rt\", \"p\",\"the\",\"th\", \"n\", \"was\"]\n",
    "\n",
    "def cleantext(df, words_to_remove=words_remove):\n",
    "    # removing emoticons from th tweets, wont help in topic modelling or semantic processing\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'<ed>','', regex = True)\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\B<U+.*>|<U+.*>\\B|<U+.*>','', regex = True)\n",
    "    \n",
    "    # convert tweets to lowercase\n",
    "    df['cleaned_tweet']=df['cleaned_tweet'].str.lower()\n",
    "    \n",
    "    # remove user mentions\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(@\\w+)',\"\", regex=True)\n",
    "    \n",
    "    # remove 'rt' or retweet in the beginning\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(rt @)',\"\",regex=True)\n",
    "    \n",
    "    #remove symbols\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[^a-zA-Z0-9]', \" \",regex=True)\n",
    "    \n",
    "    #remove punctuations\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[[]!\"#$%\\'()\\*+,-./:;<=>?^_`{|}]+',\"\", regex = True)\n",
    "    \n",
    "    #remove_URL(x)\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'https.*$',\"\",regex=True)\n",
    "    \n",
    "    # remove 'amp' in the text\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'amp',\"\",regex=True)\n",
    "    \n",
    "    #remove words of length 1 or 2\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\b[a-zA-Z]{1,2}\\b',\"\",regex=True)\n",
    "    \n",
    "    #remove extra spaces in the tweet\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^\\s+|\\s+$',\" \", regex=True)\n",
    "    \n",
    "    #remove stopwords and words_to_remove\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    mystopwords=[stop_words,'via',words_remove]\n",
    "    \n",
    "    # removing stopwords\n",
    "    df['fully_cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in mystopwords]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "#get the processed tweets\n",
    "df=cleantext(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03824,
     "end_time": "2021-05-19T06:51:31.925323",
     "exception": false,
     "start_time": "2021-05-19T06:51:31.887083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:32.008707Z",
     "iopub.status.busy": "2021-05-19T06:51:32.008029Z",
     "iopub.status.idle": "2021-05-19T06:51:34.459722Z",
     "shell.execute_reply": "2021-05-19T06:51:34.459069Z"
    },
    "papermill": {
     "duration": 2.495537,
     "end_time": "2021-05-19T06:51:34.459850",
     "exception": false,
     "start_time": "2021-05-19T06:51:31.964313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "df['sentiment']=df['fully_cleaned_tweet'].apply(lambda x:TextBlob(x).sentiment.polarity) #range -1 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:34.550253Z",
     "iopub.status.busy": "2021-05-19T06:51:34.549196Z",
     "iopub.status.idle": "2021-05-19T06:51:34.559731Z",
     "shell.execute_reply": "2021-05-19T06:51:34.559053Z"
    },
    "papermill": {
     "duration": 0.061534,
     "end_time": "2021-05-19T06:51:34.559844",
     "exception": false,
     "start_time": "2021-05-19T06:51:34.498310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>rssurjewala  critical question  was paytm info...</td>\n",
       "      <td>rssurjewala critical question was paytm inform...</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  RT @rssurjewala: Critical question: Was PayTM ...   \n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  rssurjewala  critical question  was paytm info...   \n",
       "1  hemant 80  did you vote   demonetization  modi...   \n",
       "\n",
       "                                 fully_cleaned_tweet  sentiment  \n",
       "0  rssurjewala critical question was paytm inform...       0.15  \n",
       "1  hemant 80 did you vote demonetization modi sur...       0.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038703,
     "end_time": "2021-05-19T06:51:34.637739",
     "exception": false,
     "start_time": "2021-05-19T06:51:34.599036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 3: Vectorize the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:34.721364Z",
     "iopub.status.busy": "2021-05-19T06:51:34.720651Z",
     "iopub.status.idle": "2021-05-19T06:51:37.008264Z",
     "shell.execute_reply": "2021-05-19T06:51:37.008884Z"
    },
    "papermill": {
     "duration": 2.332365,
     "end_time": "2021-05-19T06:51:37.009036",
     "exception": false,
     "start_time": "2021-05-19T06:51:34.676671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>rssurjewala  critical question  was paytm info...</td>\n",
       "      <td>rssurjewala critical question was paytm inform...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[rssurjewala, critical, question, was, paytm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[hemant, 80, did, you, vote, demonetization, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  RT @rssurjewala: Critical question: Was PayTM ...   \n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  rssurjewala  critical question  was paytm info...   \n",
       "1  hemant 80  did you vote   demonetization  modi...   \n",
       "\n",
       "                                 fully_cleaned_tweet  sentiment  \\\n",
       "0  rssurjewala critical question was paytm inform...       0.15   \n",
       "1  hemant 80 did you vote demonetization modi sur...       0.00   \n",
       "\n",
       "                                     tokenized_tweet  \n",
       "0  [rssurjewala, critical, question, was, paytm, ...  \n",
       "1  [hemant, 80, did, you, vote, demonetization, m...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweet']=df['fully_cleaned_tweet'].apply(word_tokenize)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:37.131359Z",
     "iopub.status.busy": "2021-05-19T06:51:37.120855Z",
     "iopub.status.idle": "2021-05-19T06:51:37.272515Z",
     "shell.execute_reply": "2021-05-19T06:51:37.271969Z"
    },
    "papermill": {
     "duration": 0.223669,
     "end_time": "2021-05-19T06:51:37.272639",
     "exception": false,
     "start_time": "2021-05-19T06:51:37.048970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if a word has a digit, remove that word\n",
    "df['tokenized_tweet']=df['tokenized_tweet'].apply(lambda x: [y for y in x if not any(c.isdigit() for c in y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:37.359180Z",
     "iopub.status.busy": "2021-05-19T06:51:37.358227Z",
     "iopub.status.idle": "2021-05-19T06:51:37.361432Z",
     "shell.execute_reply": "2021-05-19T06:51:37.360833Z"
    },
    "papermill": {
     "duration": 0.047909,
     "end_time": "2021-05-19T06:51:37.361536",
     "exception": false,
     "start_time": "2021-05-19T06:51:37.313627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features=100 # Word vector dimensionality\n",
    "min_word_count=1 # minimum word count\n",
    "num_workers=4  # Number of threads to run in parallel\n",
    "context=10 # context window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:37.447930Z",
     "iopub.status.busy": "2021-05-19T06:51:37.447300Z",
     "iopub.status.idle": "2021-05-19T06:51:41.379767Z",
     "shell.execute_reply": "2021-05-19T06:51:41.379040Z"
    },
    "papermill": {
     "duration": 3.978139,
     "end_time": "2021-05-19T06:51:41.379895",
     "exception": false,
     "start_time": "2021-05-19T06:51:37.401756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model....\n"
     ]
    }
   ],
   "source": [
    "# Initilaize and train the model \n",
    "from gensim.models import word2vec\n",
    "print('Training Model....')\n",
    "model= word2vec.Word2Vec(df['tokenized_tweet'],workers=num_workers,size=num_features,min_count=min_word_count,\n",
    "                        window=context)\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040421,
     "end_time": "2021-05-19T06:51:41.460986",
     "exception": false,
     "start_time": "2021-05-19T06:51:41.420565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Find vector corresponding to each tweet\n",
    "Take the average of all word vectors in a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:41.557568Z",
     "iopub.status.busy": "2021-05-19T06:51:41.551352Z",
     "iopub.status.idle": "2021-05-19T06:51:47.375989Z",
     "shell.execute_reply": "2021-05-19T06:51:47.375320Z"
    },
    "papermill": {
     "duration": 5.874228,
     "end_time": "2021-05-19T06:51:47.376108",
     "exception": false,
     "start_time": "2021-05-19T06:51:41.501880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "vocab=list(model.wv.vocab)\n",
    "def sentence_vector(sentence, model):\n",
    "    nwords=0\n",
    "    featureV=np.zeros(100, dtype='float32')\n",
    "    for word in sentence:\n",
    "        if word not in vocab:\n",
    "            continue\n",
    "        featureV=np.add(featureV, model[word])\n",
    "        nwords=nwords+1\n",
    "    if nwords>0:\n",
    "        featureV=np.divide(featureV,nwords)\n",
    "    return featureV\n",
    "\n",
    "tweet_vector= df['tokenized_tweet'].apply(lambda x: sentence_vector(x,model))\n",
    "tweet_vector= tweet_vector.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:51:47.502471Z",
     "iopub.status.busy": "2021-05-19T06:51:47.492748Z",
     "iopub.status.idle": "2021-05-19T06:53:22.977771Z",
     "shell.execute_reply": "2021-05-19T06:53:22.976344Z"
    },
    "papermill": {
     "duration": 95.560549,
     "end_time": "2021-05-19T06:53:22.977902",
     "exception": false,
     "start_time": "2021-05-19T06:51:47.417353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tweet vector should vary from 0 to 1 (normalise the vector)\n",
    "#Tweet vector should vary from 0 to 1 (normalize the vector)\n",
    "for x in range(len(tweet_vector)):\n",
    "    x_min = tweet_vector.iloc[x].min()\n",
    "    x_max = tweet_vector.iloc[x].max()\n",
    "    X  = tweet_vector.iloc[x]\n",
    "    i = 0\n",
    "    if (x_max - x_min) == 0:\n",
    "        for y in X:\n",
    "            tweet_vector.iloc[x][i] = (1/len(tweet_vector.iloc[x]))\n",
    "            i = i + 1\n",
    "    else:\n",
    "        for y in X:\n",
    "            tweet_vector.iloc[x][i] = ((y - x_min)/(x_max - x_min))\n",
    "            i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:23.066936Z",
     "iopub.status.busy": "2021-05-19T06:53:23.066277Z",
     "iopub.status.idle": "2021-05-19T06:53:23.095226Z",
     "shell.execute_reply": "2021-05-19T06:53:23.095735Z"
    },
    "papermill": {
     "duration": 0.075988,
     "end_time": "2021-05-19T06:53:23.095889",
     "exception": false,
     "start_time": "2021-05-19T06:53:23.019901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372837</td>\n",
       "      <td>0.545694</td>\n",
       "      <td>0.312134</td>\n",
       "      <td>0.406155</td>\n",
       "      <td>0.419439</td>\n",
       "      <td>0.131938</td>\n",
       "      <td>0.516665</td>\n",
       "      <td>0.455538</td>\n",
       "      <td>0.305514</td>\n",
       "      <td>0.341636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300012</td>\n",
       "      <td>0.382390</td>\n",
       "      <td>0.733279</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>0.375121</td>\n",
       "      <td>0.293636</td>\n",
       "      <td>0.615567</td>\n",
       "      <td>0.155568</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.663150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.377996</td>\n",
       "      <td>0.521854</td>\n",
       "      <td>0.181112</td>\n",
       "      <td>0.599348</td>\n",
       "      <td>0.408489</td>\n",
       "      <td>0.395992</td>\n",
       "      <td>0.599420</td>\n",
       "      <td>0.261847</td>\n",
       "      <td>0.392707</td>\n",
       "      <td>0.225454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434284</td>\n",
       "      <td>0.505318</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.246737</td>\n",
       "      <td>0.284222</td>\n",
       "      <td>0.398768</td>\n",
       "      <td>0.678347</td>\n",
       "      <td>0.239313</td>\n",
       "      <td>0.863538</td>\n",
       "      <td>0.617505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343447</td>\n",
       "      <td>0.531399</td>\n",
       "      <td>0.203889</td>\n",
       "      <td>0.381148</td>\n",
       "      <td>0.416401</td>\n",
       "      <td>0.272614</td>\n",
       "      <td>0.535161</td>\n",
       "      <td>0.117553</td>\n",
       "      <td>0.402884</td>\n",
       "      <td>0.249198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388092</td>\n",
       "      <td>0.473040</td>\n",
       "      <td>0.488666</td>\n",
       "      <td>0.314732</td>\n",
       "      <td>0.304895</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.630012</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.735415</td>\n",
       "      <td>0.631259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294992</td>\n",
       "      <td>0.522601</td>\n",
       "      <td>0.236966</td>\n",
       "      <td>0.390040</td>\n",
       "      <td>0.415191</td>\n",
       "      <td>0.324684</td>\n",
       "      <td>0.533012</td>\n",
       "      <td>0.089598</td>\n",
       "      <td>0.409144</td>\n",
       "      <td>0.237142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383553</td>\n",
       "      <td>0.467209</td>\n",
       "      <td>0.459293</td>\n",
       "      <td>0.388277</td>\n",
       "      <td>0.316471</td>\n",
       "      <td>0.414858</td>\n",
       "      <td>0.606502</td>\n",
       "      <td>0.049513</td>\n",
       "      <td>0.727050</td>\n",
       "      <td>0.664490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.391451</td>\n",
       "      <td>0.329246</td>\n",
       "      <td>0.220099</td>\n",
       "      <td>0.279498</td>\n",
       "      <td>0.395203</td>\n",
       "      <td>0.402952</td>\n",
       "      <td>0.436287</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.399426</td>\n",
       "      <td>0.325041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351659</td>\n",
       "      <td>0.475781</td>\n",
       "      <td>0.483794</td>\n",
       "      <td>0.390450</td>\n",
       "      <td>0.169674</td>\n",
       "      <td>0.343840</td>\n",
       "      <td>0.521581</td>\n",
       "      <td>0.145253</td>\n",
       "      <td>0.765088</td>\n",
       "      <td>0.522121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.341186</td>\n",
       "      <td>0.548719</td>\n",
       "      <td>0.232380</td>\n",
       "      <td>0.495930</td>\n",
       "      <td>0.497329</td>\n",
       "      <td>0.217148</td>\n",
       "      <td>0.574678</td>\n",
       "      <td>0.119535</td>\n",
       "      <td>0.385406</td>\n",
       "      <td>0.230178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519348</td>\n",
       "      <td>0.418279</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.290040</td>\n",
       "      <td>0.312487</td>\n",
       "      <td>0.414291</td>\n",
       "      <td>0.538317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.665764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.515508</td>\n",
       "      <td>0.531603</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.379006</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>0.225876</td>\n",
       "      <td>0.525852</td>\n",
       "      <td>0.287786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371843</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.258661</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.518822</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.262985</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.648654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.494650</td>\n",
       "      <td>0.543870</td>\n",
       "      <td>0.280147</td>\n",
       "      <td>0.483720</td>\n",
       "      <td>0.497321</td>\n",
       "      <td>0.307066</td>\n",
       "      <td>0.628304</td>\n",
       "      <td>0.326802</td>\n",
       "      <td>0.406790</td>\n",
       "      <td>0.287471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544162</td>\n",
       "      <td>0.505814</td>\n",
       "      <td>0.519237</td>\n",
       "      <td>0.248153</td>\n",
       "      <td>0.375796</td>\n",
       "      <td>0.488674</td>\n",
       "      <td>0.675969</td>\n",
       "      <td>0.277095</td>\n",
       "      <td>0.752114</td>\n",
       "      <td>0.564119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.515508</td>\n",
       "      <td>0.531603</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.379006</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>0.225876</td>\n",
       "      <td>0.525852</td>\n",
       "      <td>0.287786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371843</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.258661</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.518822</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.262985</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.648654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.515508</td>\n",
       "      <td>0.531603</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.379006</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>0.225876</td>\n",
       "      <td>0.525852</td>\n",
       "      <td>0.287786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371843</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.258661</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.518822</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.262985</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.648654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.372837  0.545694  0.312134  0.406155  0.419439  0.131938  0.516665   \n",
       "1     0.377996  0.521854  0.181112  0.599348  0.408489  0.395992  0.599420   \n",
       "2     0.343447  0.531399  0.203889  0.381148  0.416401  0.272614  0.535161   \n",
       "3     0.294992  0.522601  0.236966  0.390040  0.415191  0.324684  0.533012   \n",
       "4     0.391451  0.329246  0.220099  0.279498  0.395203  0.402952  0.436287   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.341186  0.548719  0.232380  0.495930  0.497329  0.217148  0.574678   \n",
       "9996  0.515508  0.531603  0.165854  0.416848  0.427287  0.379006  0.552947   \n",
       "9997  0.494650  0.543870  0.280147  0.483720  0.497321  0.307066  0.628304   \n",
       "9998  0.515508  0.531603  0.165854  0.416848  0.427287  0.379006  0.552947   \n",
       "9999  0.515508  0.531603  0.165854  0.416848  0.427287  0.379006  0.552947   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.455538  0.305514  0.341636  ...  0.300012  0.382390  0.733279   \n",
       "1     0.261847  0.392707  0.225454  ...  0.434284  0.505318  0.438099   \n",
       "2     0.117553  0.402884  0.249198  ...  0.388092  0.473040  0.488666   \n",
       "3     0.089598  0.409144  0.237142  ...  0.383553  0.467209  0.459293   \n",
       "4     0.013495  0.399426  0.325041  ...  0.351659  0.475781  0.483794   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.119535  0.385406  0.230178  ...  0.519348  0.418279  0.539634   \n",
       "9996  0.225876  0.525852  0.287786  ...  0.371843  0.614178  0.463436   \n",
       "9997  0.326802  0.406790  0.287471  ...  0.544162  0.505814  0.519237   \n",
       "9998  0.225876  0.525852  0.287786  ...  0.371843  0.614178  0.463436   \n",
       "9999  0.225876  0.525852  0.287786  ...  0.371843  0.614178  0.463436   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.027603  0.375121  0.293636  0.615567  0.155568  0.644286  0.663150  \n",
       "1     0.246737  0.284222  0.398768  0.678347  0.239313  0.863538  0.617505  \n",
       "2     0.314732  0.304895  0.406100  0.630012  0.078014  0.735415  0.631259  \n",
       "3     0.388277  0.316471  0.414858  0.606502  0.049513  0.727050  0.664490  \n",
       "4     0.390450  0.169674  0.343840  0.521581  0.145253  0.765088  0.522121  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995  0.290040  0.312487  0.414291  0.538317  0.000000  0.649007  0.665764  \n",
       "9996  0.258661  0.351038  0.518822  0.777970  0.262985  0.928042  0.648654  \n",
       "9997  0.248153  0.375796  0.488674  0.675969  0.277095  0.752114  0.564119  \n",
       "9998  0.258661  0.351038  0.518822  0.777970  0.262985  0.928042  0.648654  \n",
       "9999  0.258661  0.351038  0.518822  0.777970  0.262985  0.928042  0.648654  \n",
       "\n",
       "[10000 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042414,
     "end_time": "2021-05-19T06:53:23.180801",
     "exception": false,
     "start_time": "2021-05-19T06:53:23.138387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 4: Add sentiment to the tweet vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:23.281042Z",
     "iopub.status.busy": "2021-05-19T06:53:23.280384Z",
     "iopub.status.idle": "2021-05-19T06:53:23.283034Z",
     "shell.execute_reply": "2021-05-19T06:53:23.283486Z"
    },
    "papermill": {
     "duration": 0.060824,
     "end_time": "2021-05-19T06:53:23.283647",
     "exception": false,
     "start_time": "2021-05-19T06:53:23.222823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the 'sentiment' vector\n",
    "# Sentiment varies from -1(Negative Sentiment) to +1(Positive Sentiment) polarity\n",
    "def sentiment(x):\n",
    "    if x < 0.04:\n",
    "        return 0 #(Neutral sentiment)\n",
    "    elif x>0.04:\n",
    "        return 1 #(Positive Sentiment)\n",
    "    else:\n",
    "        return 0.5 #(Negative Sentiment)\n",
    "\n",
    "tweet_vector[100]=df['sentiment'].apply(lambda x: sentiment(x)) # Adding 100 coumn for sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:23.376710Z",
     "iopub.status.busy": "2021-05-19T06:53:23.376060Z",
     "iopub.status.idle": "2021-05-19T06:53:23.405604Z",
     "shell.execute_reply": "2021-05-19T06:53:23.404992Z"
    },
    "papermill": {
     "duration": 0.078733,
     "end_time": "2021-05-19T06:53:23.405732",
     "exception": false,
     "start_time": "2021-05-19T06:53:23.326999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372837</td>\n",
       "      <td>0.545694</td>\n",
       "      <td>0.312134</td>\n",
       "      <td>0.406155</td>\n",
       "      <td>0.419439</td>\n",
       "      <td>0.131938</td>\n",
       "      <td>0.516665</td>\n",
       "      <td>0.455538</td>\n",
       "      <td>0.305514</td>\n",
       "      <td>0.341636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382390</td>\n",
       "      <td>0.733279</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>0.375121</td>\n",
       "      <td>0.293636</td>\n",
       "      <td>0.615567</td>\n",
       "      <td>0.155568</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.663150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.377996</td>\n",
       "      <td>0.521854</td>\n",
       "      <td>0.181112</td>\n",
       "      <td>0.599348</td>\n",
       "      <td>0.408489</td>\n",
       "      <td>0.395992</td>\n",
       "      <td>0.599420</td>\n",
       "      <td>0.261847</td>\n",
       "      <td>0.392707</td>\n",
       "      <td>0.225454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505318</td>\n",
       "      <td>0.438099</td>\n",
       "      <td>0.246737</td>\n",
       "      <td>0.284222</td>\n",
       "      <td>0.398768</td>\n",
       "      <td>0.678347</td>\n",
       "      <td>0.239313</td>\n",
       "      <td>0.863538</td>\n",
       "      <td>0.617505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343447</td>\n",
       "      <td>0.531399</td>\n",
       "      <td>0.203889</td>\n",
       "      <td>0.381148</td>\n",
       "      <td>0.416401</td>\n",
       "      <td>0.272614</td>\n",
       "      <td>0.535161</td>\n",
       "      <td>0.117553</td>\n",
       "      <td>0.402884</td>\n",
       "      <td>0.249198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473040</td>\n",
       "      <td>0.488666</td>\n",
       "      <td>0.314732</td>\n",
       "      <td>0.304895</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.630012</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.735415</td>\n",
       "      <td>0.631259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294992</td>\n",
       "      <td>0.522601</td>\n",
       "      <td>0.236966</td>\n",
       "      <td>0.390040</td>\n",
       "      <td>0.415191</td>\n",
       "      <td>0.324684</td>\n",
       "      <td>0.533012</td>\n",
       "      <td>0.089598</td>\n",
       "      <td>0.409144</td>\n",
       "      <td>0.237142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467209</td>\n",
       "      <td>0.459293</td>\n",
       "      <td>0.388277</td>\n",
       "      <td>0.316471</td>\n",
       "      <td>0.414858</td>\n",
       "      <td>0.606502</td>\n",
       "      <td>0.049513</td>\n",
       "      <td>0.727050</td>\n",
       "      <td>0.664490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.391451</td>\n",
       "      <td>0.329246</td>\n",
       "      <td>0.220099</td>\n",
       "      <td>0.279498</td>\n",
       "      <td>0.395203</td>\n",
       "      <td>0.402952</td>\n",
       "      <td>0.436287</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.399426</td>\n",
       "      <td>0.325041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475781</td>\n",
       "      <td>0.483794</td>\n",
       "      <td>0.390450</td>\n",
       "      <td>0.169674</td>\n",
       "      <td>0.343840</td>\n",
       "      <td>0.521581</td>\n",
       "      <td>0.145253</td>\n",
       "      <td>0.765088</td>\n",
       "      <td>0.522121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.341186</td>\n",
       "      <td>0.548719</td>\n",
       "      <td>0.232380</td>\n",
       "      <td>0.495930</td>\n",
       "      <td>0.497329</td>\n",
       "      <td>0.217148</td>\n",
       "      <td>0.574678</td>\n",
       "      <td>0.119535</td>\n",
       "      <td>0.385406</td>\n",
       "      <td>0.230178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418279</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.290040</td>\n",
       "      <td>0.312487</td>\n",
       "      <td>0.414291</td>\n",
       "      <td>0.538317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.665764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.515508</td>\n",
       "      <td>0.531603</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.379006</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>0.225876</td>\n",
       "      <td>0.525852</td>\n",
       "      <td>0.287786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.258661</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.518822</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.262985</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.648654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.494650</td>\n",
       "      <td>0.543870</td>\n",
       "      <td>0.280147</td>\n",
       "      <td>0.483720</td>\n",
       "      <td>0.497321</td>\n",
       "      <td>0.307066</td>\n",
       "      <td>0.628304</td>\n",
       "      <td>0.326802</td>\n",
       "      <td>0.406790</td>\n",
       "      <td>0.287471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505814</td>\n",
       "      <td>0.519237</td>\n",
       "      <td>0.248153</td>\n",
       "      <td>0.375796</td>\n",
       "      <td>0.488674</td>\n",
       "      <td>0.675969</td>\n",
       "      <td>0.277095</td>\n",
       "      <td>0.752114</td>\n",
       "      <td>0.564119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.515508</td>\n",
       "      <td>0.531603</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.379006</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>0.225876</td>\n",
       "      <td>0.525852</td>\n",
       "      <td>0.287786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.258661</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.518822</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.262985</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.648654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.515508</td>\n",
       "      <td>0.531603</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.379006</td>\n",
       "      <td>0.552947</td>\n",
       "      <td>0.225876</td>\n",
       "      <td>0.525852</td>\n",
       "      <td>0.287786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.258661</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.518822</td>\n",
       "      <td>0.777970</td>\n",
       "      <td>0.262985</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.648654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.372837  0.545694  0.312134  0.406155  0.419439  0.131938  0.516665   \n",
       "1     0.377996  0.521854  0.181112  0.599348  0.408489  0.395992  0.599420   \n",
       "2     0.343447  0.531399  0.203889  0.381148  0.416401  0.272614  0.535161   \n",
       "3     0.294992  0.522601  0.236966  0.390040  0.415191  0.324684  0.533012   \n",
       "4     0.391451  0.329246  0.220099  0.279498  0.395203  0.402952  0.436287   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.341186  0.548719  0.232380  0.495930  0.497329  0.217148  0.574678   \n",
       "9996  0.515508  0.531603  0.165854  0.416848  0.427287  0.379006  0.552947   \n",
       "9997  0.494650  0.543870  0.280147  0.483720  0.497321  0.307066  0.628304   \n",
       "9998  0.515508  0.531603  0.165854  0.416848  0.427287  0.379006  0.552947   \n",
       "9999  0.515508  0.531603  0.165854  0.416848  0.427287  0.379006  0.552947   \n",
       "\n",
       "           7         8         9    ...       91        92        93   \\\n",
       "0     0.455538  0.305514  0.341636  ...  0.382390  0.733279  0.027603   \n",
       "1     0.261847  0.392707  0.225454  ...  0.505318  0.438099  0.246737   \n",
       "2     0.117553  0.402884  0.249198  ...  0.473040  0.488666  0.314732   \n",
       "3     0.089598  0.409144  0.237142  ...  0.467209  0.459293  0.388277   \n",
       "4     0.013495  0.399426  0.325041  ...  0.475781  0.483794  0.390450   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.119535  0.385406  0.230178  ...  0.418279  0.539634  0.290040   \n",
       "9996  0.225876  0.525852  0.287786  ...  0.614178  0.463436  0.258661   \n",
       "9997  0.326802  0.406790  0.287471  ...  0.505814  0.519237  0.248153   \n",
       "9998  0.225876  0.525852  0.287786  ...  0.614178  0.463436  0.258661   \n",
       "9999  0.225876  0.525852  0.287786  ...  0.614178  0.463436  0.258661   \n",
       "\n",
       "           94        95        96        97        98        99   100  \n",
       "0     0.375121  0.293636  0.615567  0.155568  0.644286  0.663150    1  \n",
       "1     0.284222  0.398768  0.678347  0.239313  0.863538  0.617505    0  \n",
       "2     0.304895  0.406100  0.630012  0.078014  0.735415  0.631259    0  \n",
       "3     0.316471  0.414858  0.606502  0.049513  0.727050  0.664490    0  \n",
       "4     0.169674  0.343840  0.521581  0.145253  0.765088  0.522121    0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "9995  0.312487  0.414291  0.538317  0.000000  0.649007  0.665764    0  \n",
       "9996  0.351038  0.518822  0.777970  0.262985  0.928042  0.648654    1  \n",
       "9997  0.375796  0.488674  0.675969  0.277095  0.752114  0.564119    1  \n",
       "9998  0.351038  0.518822  0.777970  0.262985  0.928042  0.648654    1  \n",
       "9999  0.351038  0.518822  0.777970  0.262985  0.928042  0.648654    1  \n",
       "\n",
       "[10000 rows x 101 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:23.506161Z",
     "iopub.status.busy": "2021-05-19T06:53:23.505467Z",
     "iopub.status.idle": "2021-05-19T06:53:23.509466Z",
     "shell.execute_reply": "2021-05-19T06:53:23.508975Z"
    },
    "papermill": {
     "duration": 0.060325,
     "end_time": "2021-05-19T06:53:23.509574",
     "exception": false,
     "start_time": "2021-05-19T06:53:23.449249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>rssurjewala  critical question  was paytm info...</td>\n",
       "      <td>rssurjewala critical question was paytm inform...</td>\n",
       "      <td>1</td>\n",
       "      <td>[rssurjewala, critical, question, was, paytm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hemant, did, you, vote, demonetization, modi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt ch...</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chai...</td>\n",
       "      <td>0</td>\n",
       "      <td>[roshankar, former, finsec, rbi, governor, cbd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  RT @rssurjewala: Critical question: Was PayTM ...   \n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  rssurjewala  critical question  was paytm info...   \n",
       "1  hemant 80  did you vote   demonetization  modi...   \n",
       "2  roshankar  former finsec rbi  governor cbdt ch...   \n",
       "\n",
       "                                 fully_cleaned_tweet  sentiment  \\\n",
       "0  rssurjewala critical question was paytm inform...          1   \n",
       "1  hemant 80 did you vote demonetization modi sur...          0   \n",
       "2  roshankar former finsec rbi governor cbdt chai...          0   \n",
       "\n",
       "                                     tokenized_tweet  \n",
       "0  [rssurjewala, critical, question, was, paytm, ...  \n",
       "1  [hemant, did, you, vote, demonetization, modi,...  \n",
       "2  [roshankar, former, finsec, rbi, governor, cbd...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updating the 'sentiment' column in df also\n",
    "df['sentiment'] = tweet_vector[100]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04416,
     "end_time": "2021-05-19T06:53:23.598060",
     "exception": false,
     "start_time": "2021-05-19T06:53:23.553900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 5: Cluster the narratives [= opinions + expressions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:23.695705Z",
     "iopub.status.busy": "2021-05-19T06:53:23.694975Z",
     "iopub.status.idle": "2021-05-19T06:53:41.820329Z",
     "shell.execute_reply": "2021-05-19T06:53:41.819582Z"
    },
    "papermill": {
     "duration": 18.177597,
     "end_time": "2021-05-19T06:53:41.820503",
     "exception": false,
     "start_time": "2021-05-19T06:53:23.642906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 4 The average silhouette_score is : 0.2307716752455403\n",
      "For n_clusters = 6 The average silhouette_score is : 0.25704949795338566\n",
      "For n_clusters = 7 The average silhouette_score is : 0.28307576663345596\n",
      "For n_clusters = 8 The average silhouette_score is : 0.2795376765963954\n",
      "For n_clusters = 9 The average silhouette_score is : 0.3089161759532428\n",
      "For n_clusters = 10 The average silhouette_score is : 0.306817928946136\n",
      "For n_clusters = 11 The average silhouette_score is : 0.3116391187095521\n",
      "For n_clusters = 12 The average silhouette_score is : 0.3274158684148053\n",
      "For n_clusters = 14 The average silhouette_score is : 0.31695794523603954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score,silhouette_samples\n",
    "\n",
    "range_n_clusters=[4,6,7,8,9,10,11,12,14]\n",
    "X= tweet_vector\n",
    "n_best_clusters=0\n",
    "silhouette_best = 0\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.  \n",
    "    clusterer=KMeans(n_clusters=n_clusters,random_state=42)\n",
    "    cluster_labels=clusterer.fit_predict(X)\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg=silhouette_score(X,cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    if silhouette_avg > silhouette_best:\n",
    "        silhouette_best = silhouette_avg\n",
    "        n_best_clusters = n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:41.920783Z",
     "iopub.status.busy": "2021-05-19T06:53:41.919994Z",
     "iopub.status.idle": "2021-05-19T06:53:41.925341Z",
     "shell.execute_reply": "2021-05-19T06:53:41.924797Z"
    },
    "papermill": {
     "duration": 0.057088,
     "end_time": "2021-05-19T06:53:41.925453",
     "exception": false,
     "start_time": "2021-05-19T06:53:41.868365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0.3274158684148053\n"
     ]
    }
   ],
   "source": [
    "print(n_best_clusters)\n",
    "print(silhouette_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:42.032489Z",
     "iopub.status.busy": "2021-05-19T06:53:42.031203Z",
     "iopub.status.idle": "2021-05-19T06:53:42.759828Z",
     "shell.execute_reply": "2021-05-19T06:53:42.760417Z"
    },
    "papermill": {
     "duration": 0.785636,
     "end_time": "2021-05-19T06:53:42.760571",
     "exception": false,
     "start_time": "2021-05-19T06:53:41.974935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusterer=KMeans(n_clusters=n_best_clusters,random_state=42)\n",
    "cluster_labels=clusterer.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:42.891689Z",
     "iopub.status.busy": "2021-05-19T06:53:42.890646Z",
     "iopub.status.idle": "2021-05-19T06:53:42.896169Z",
     "shell.execute_reply": "2021-05-19T06:53:42.896882Z"
    },
    "papermill": {
     "duration": 0.073779,
     "end_time": "2021-05-19T06:53:42.897054",
     "exception": false,
     "start_time": "2021-05-19T06:53:42.823275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:43.014730Z",
     "iopub.status.busy": "2021-05-19T06:53:43.013983Z",
     "iopub.status.idle": "2021-05-19T06:53:43.021600Z",
     "shell.execute_reply": "2021-05-19T06:53:43.020913Z"
    },
    "papermill": {
     "duration": 0.064703,
     "end_time": "2021-05-19T06:53:43.021713",
     "exception": false,
     "start_time": "2021-05-19T06:53:42.957010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Array of tweets, the corresponding cluster number, sentiment\n",
    "finaldf = pd.DataFrame({'cl_num': cluster_labels,'fully_cleaned_tweet': df['fully_cleaned_tweet'], 'cleaned_tweet': df['cleaned_tweet'], 'tweet': df['tweet'],'sentiment': df['sentiment']})\n",
    "finaldf = finaldf.sort_values(by=['cl_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:43.133032Z",
     "iopub.status.busy": "2021-05-19T06:53:43.123711Z",
     "iopub.status.idle": "2021-05-19T06:53:43.137922Z",
     "shell.execute_reply": "2021-05-19T06:53:43.137356Z"
    },
    "papermill": {
     "duration": 0.068009,
     "end_time": "2021-05-19T06:53:43.138039",
     "exception": false,
     "start_time": "2021-05-19T06:53:43.070030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>cl_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>rssurjewala  critical question  was paytm info...</td>\n",
       "      <td>rssurjewala critical question was paytm inform...</td>\n",
       "      <td>1</td>\n",
       "      <td>[rssurjewala, critical, question, was, paytm, ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>hemant 80  did you vote   demonetization  modi...</td>\n",
       "      <td>hemant 80 did you vote demonetization modi sur...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hemant, did, you, vote, demonetization, modi,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt ch...</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chai...</td>\n",
       "      <td>0</td>\n",
       "      <td>[roshankar, former, finsec, rbi, governor, cbd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  RT @rssurjewala: Critical question: Was PayTM ...   \n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  rssurjewala  critical question  was paytm info...   \n",
       "1  hemant 80  did you vote   demonetization  modi...   \n",
       "2  roshankar  former finsec rbi  governor cbdt ch...   \n",
       "\n",
       "                                 fully_cleaned_tweet  sentiment  \\\n",
       "0  rssurjewala critical question was paytm inform...          1   \n",
       "1  hemant 80 did you vote demonetization modi sur...          0   \n",
       "2  roshankar former finsec rbi governor cbdt chai...          0   \n",
       "\n",
       "                                     tokenized_tweet  cl_num  \n",
       "0  [rssurjewala, critical, question, was, paytm, ...      10  \n",
       "1  [hemant, did, you, vote, demonetization, modi,...       4  \n",
       "2  [roshankar, former, finsec, rbi, governor, cbd...       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cl_num']=cluster_labels\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:43.253544Z",
     "iopub.status.busy": "2021-05-19T06:53:43.252617Z",
     "iopub.status.idle": "2021-05-19T06:53:43.307500Z",
     "shell.execute_reply": "2021-05-19T06:53:43.306794Z"
    },
    "papermill": {
     "duration": 0.120668,
     "end_time": "2021-05-19T06:53:43.307631",
     "exception": false,
     "start_time": "2021-05-19T06:53:43.186963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfOrdered = pd.DataFrame(df)\n",
    "\n",
    "#Compute how many times a tweet has been 'retweeted' - that is, how many rows in dfOrdered are identical\n",
    "dfOrdered['tokenized_tweet'] = dfOrdered['tokenized_tweet'].apply(tuple)\n",
    "dfUnique = dfOrdered.groupby(['tweet', 'cleaned_tweet', 'fully_cleaned_tweet', 'sentiment','tokenized_tweet', 'cl_num']).size().reset_index(name=\"freq\")\n",
    "dfUnique = dfUnique.sort_values(by=['cl_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:43.432790Z",
     "iopub.status.busy": "2021-05-19T06:53:43.431777Z",
     "iopub.status.idle": "2021-05-19T06:53:43.435753Z",
     "shell.execute_reply": "2021-05-19T06:53:43.435210Z"
    },
    "papermill": {
     "duration": 0.075891,
     "end_time": "2021-05-19T06:53:43.435885",
     "exception": false,
     "start_time": "2021-05-19T06:53:43.359994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfUnique['tokenized_tweet'] = dfUnique['tokenized_tweet'].apply(list)\n",
    "dfOrdered['tokenized_tweet'] = dfOrdered['tokenized_tweet'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:43.558777Z",
     "iopub.status.busy": "2021-05-19T06:53:43.558108Z",
     "iopub.status.idle": "2021-05-19T06:53:43.562767Z",
     "shell.execute_reply": "2021-05-19T06:53:43.562242Z"
    },
    "papermill": {
     "duration": 0.077533,
     "end_time": "2021-05-19T06:53:43.562882",
     "exception": false,
     "start_time": "2021-05-19T06:53:43.485349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>cl_num</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>It's amusing to see people who have elected Tr...</td>\n",
       "      <td>its amusing  see people who have elected trump...</td>\n",
       "      <td>its amusing see people who have elected trump ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[its, amusing, see, people, who, have, elected...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>@NewsX @sushmitadevmp makes it very clear that...</td>\n",
       "      <td>sushmitadevmp makes  very clear that except f...</td>\n",
       "      <td>sushmitadevmp makes very clear that except for...</td>\n",
       "      <td>1</td>\n",
       "      <td>[sushmitadevmp, makes, very, clear, that, exce...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>@Nishith1608 It's very balanced piece BJP has ...</td>\n",
       "      <td>its very balanced piece bjp has made gains tm...</td>\n",
       "      <td>its very balanced piece bjp has made gains tmc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[its, very, balanced, piece, bjp, has, made, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>RT @muglikar_: Ughhh new spin in the market: #...</td>\n",
       "      <td>muglikar   ughhh new spin  the market   demone...</td>\n",
       "      <td>muglikar ughhh new spin the market demonetizat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[muglikar, ughhh, new, spin, the, market, demo...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>@NitishKumar Stop this fence sitting exercise,...</td>\n",
       "      <td>stop this fence sitting exercise  make your s...</td>\n",
       "      <td>stop this fence sitting exercise make your sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stop, this, fence, sitting, exercise, make, y...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>RT @rpollard: More currency shortages across I...</td>\n",
       "      <td>rpollard  more currency shortages across india...</td>\n",
       "      <td>rpollard more currency shortages across india ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[rpollard, more, currency, shortages, across, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>#news #summary:  #world  #bank backs  #demonet...</td>\n",
       "      <td>news  summary    world   bank backs   demonet...</td>\n",
       "      <td>news summary world bank backs demonetization s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[news, summary, world, bank, backs, demonetiza...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>RT @shilpakannan: India's Central Bank comes u...</td>\n",
       "      <td>shilpakannan  indias central bank comes  with ...</td>\n",
       "      <td>shilpakannan indias central bank comes with mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[shilpakannan, indias, central, bank, comes, w...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>More currency shortages across India #demoneti...</td>\n",
       "      <td>more currency shortages across india  demoneti...</td>\n",
       "      <td>more currency shortages across india demonetiz...</td>\n",
       "      <td>1</td>\n",
       "      <td>[more, currency, shortages, across, india, dem...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Economic impact of #demonetization : Smaller S...</td>\n",
       "      <td>economic impact   demonetization   smaller sho...</td>\n",
       "      <td>economic impact demonetization smaller showroo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[economic, impact, demonetization, smaller, sh...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3485 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "1623  It's amusing to see people who have elected Tr...   \n",
       "659   @NewsX @sushmitadevmp makes it very clear that...   \n",
       "660   @Nishith1608 It's very balanced piece BJP has ...   \n",
       "2683  RT @muglikar_: Ughhh new spin in the market: #...   \n",
       "662   @NitishKumar Stop this fence sitting exercise,...   \n",
       "...                                                 ...   \n",
       "2768  RT @rpollard: More currency shortages across I...   \n",
       "407   #news #summary:  #world  #bank backs  #demonet...   \n",
       "2809  RT @shilpakannan: India's Central Bank comes u...   \n",
       "1715  More currency shortages across India #demoneti...   \n",
       "1311  Economic impact of #demonetization : Smaller S...   \n",
       "\n",
       "                                          cleaned_tweet  \\\n",
       "1623  its amusing  see people who have elected trump...   \n",
       "659    sushmitadevmp makes  very clear that except f...   \n",
       "660    its very balanced piece bjp has made gains tm...   \n",
       "2683  muglikar   ughhh new spin  the market   demone...   \n",
       "662    stop this fence sitting exercise  make your s...   \n",
       "...                                                 ...   \n",
       "2768  rpollard  more currency shortages across india...   \n",
       "407    news  summary    world   bank backs   demonet...   \n",
       "2809  shilpakannan  indias central bank comes  with ...   \n",
       "1715  more currency shortages across india  demoneti...   \n",
       "1311  economic impact   demonetization   smaller sho...   \n",
       "\n",
       "                                    fully_cleaned_tweet  sentiment  \\\n",
       "1623  its amusing see people who have elected trump ...          1   \n",
       "659   sushmitadevmp makes very clear that except for...          1   \n",
       "660   its very balanced piece bjp has made gains tmc...          1   \n",
       "2683  muglikar ughhh new spin the market demonetizat...          1   \n",
       "662   stop this fence sitting exercise make your sta...          1   \n",
       "...                                                 ...        ...   \n",
       "2768  rpollard more currency shortages across india ...          1   \n",
       "407   news summary world bank backs demonetization s...          1   \n",
       "2809  shilpakannan indias central bank comes with mo...          1   \n",
       "1715  more currency shortages across india demonetiz...          1   \n",
       "1311  economic impact demonetization smaller showroo...          1   \n",
       "\n",
       "                                        tokenized_tweet  cl_num  freq  \n",
       "1623  [its, amusing, see, people, who, have, elected...       0     1  \n",
       "659   [sushmitadevmp, makes, very, clear, that, exce...       0     1  \n",
       "660   [its, very, balanced, piece, bjp, has, made, g...       0     1  \n",
       "2683  [muglikar, ughhh, new, spin, the, market, demo...       0     9  \n",
       "662   [stop, this, fence, sitting, exercise, make, y...       0     1  \n",
       "...                                                 ...     ...   ...  \n",
       "2768  [rpollard, more, currency, shortages, across, ...      11     1  \n",
       "407   [news, summary, world, bank, backs, demonetiza...      11     1  \n",
       "2809  [shilpakannan, indias, central, bank, comes, w...      11     3  \n",
       "1715  [more, currency, shortages, across, india, dem...      11     1  \n",
       "1311  [economic, impact, demonetization, smaller, sh...      11     1  \n",
       "\n",
       "[3485 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUnique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04967,
     "end_time": "2021-05-19T06:53:43.662442",
     "exception": false,
     "start_time": "2021-05-19T06:53:43.612772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Discard the clusters with poor Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:43.766917Z",
     "iopub.status.busy": "2021-05-19T06:53:43.766211Z",
     "iopub.status.idle": "2021-05-19T06:53:45.116189Z",
     "shell.execute_reply": "2021-05-19T06:53:45.114824Z"
    },
    "papermill": {
     "duration": 1.403935,
     "end_time": "2021-05-19T06:53:45.116324",
     "exception": false,
     "start_time": "2021-05-19T06:53:43.712389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 : 0.23703967775473345\n",
      "Cluster 1 : 0.3092625822574267\n",
      "Cluster 2 : 0.3434782819851654\n",
      "Cluster 3 : 0.5191241697375981\n",
      "Cluster 4 : 0.13044861714973333\n",
      "Cluster 5 : 0.4560368695953895\n",
      "Cluster 6 : 0.41968844808574157\n",
      "Cluster 7 : 0.31383930378836283\n",
      "Cluster 8 : 1.0\n",
      "Cluster 9 : 0.3252568605534971\n",
      "Cluster 10 : 0.4907738588146729\n",
      "Cluster 11 : 0.2169691656781262\n"
     ]
    }
   ],
   "source": [
    "# Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "poor_cluster_indices = []\n",
    "avg_cluster_sil_score = []\n",
    "\n",
    "for i in range(n_best_clusters):\n",
    "# Aggregate the silhouette scores for samples belonging to\n",
    "# cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        avgscore = (np.mean(ith_cluster_silhouette_values))   #average silhouette score for each cluster\n",
    "        avg_cluster_sil_score = np.append(avg_cluster_sil_score, avgscore)\n",
    "        print('Cluster',i, ':', avgscore)\n",
    "        if avgscore < 0.2:\n",
    "            poor_cluster_indices = np.append(poor_cluster_indices, i)\n",
    "            \n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:45.227331Z",
     "iopub.status.busy": "2021-05-19T06:53:45.226231Z",
     "iopub.status.idle": "2021-05-19T06:53:45.230928Z",
     "shell.execute_reply": "2021-05-19T06:53:45.230416Z"
    },
    "papermill": {
     "duration": 0.061991,
     "end_time": "2021-05-19T06:53:45.231040",
     "exception": false,
     "start_time": "2021-05-19T06:53:45.169049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor_cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:45.346247Z",
     "iopub.status.busy": "2021-05-19T06:53:45.345441Z",
     "iopub.status.idle": "2021-05-19T06:53:45.372265Z",
     "shell.execute_reply": "2021-05-19T06:53:45.371696Z"
    },
    "papermill": {
     "duration": 0.088193,
     "end_time": "2021-05-19T06:53:45.372376",
     "exception": false,
     "start_time": "2021-05-19T06:53:45.284183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove those rows where cluster value match poor_cluster_indices \n",
    "avg_cluster_sil_score_final = []\n",
    "cluster_name = np.unique(dfOrdered['cl_num'])\n",
    "\n",
    "if (len(poor_cluster_indices)!=0):\n",
    "    n_final_clusters = n_best_clusters - len(poor_cluster_indices)\n",
    "    for i in poor_cluster_indices:\n",
    "        dfUnique = dfUnique[dfUnique['cl_num'] != i]\n",
    "    for j in cluster_name:\n",
    "        if j not in poor_cluster_indices:    \n",
    "            avg_cluster_sil_score_final = np.append(avg_cluster_sil_score_final, avg_cluster_sil_score[j])\n",
    "            \n",
    "    cluster_name = np.unique(dfUnique['cl_num'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:45.479033Z",
     "iopub.status.busy": "2021-05-19T06:53:45.478407Z",
     "iopub.status.idle": "2021-05-19T06:53:45.486415Z",
     "shell.execute_reply": "2021-05-19T06:53:45.485753Z"
    },
    "papermill": {
     "duration": 0.062508,
     "end_time": "2021-05-19T06:53:45.486524",
     "exception": false,
     "start_time": "2021-05-19T06:53:45.424016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dfUnique['cl_num']=abs(dfUnique['cl_num'])\n",
    "dfUnique=dfUnique.sort_values(by=['cl_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052916,
     "end_time": "2021-05-19T06:53:45.592572",
     "exception": false,
     "start_time": "2021-05-19T06:53:45.539656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 6: Calculate abstraction and expression for each narrative \n",
    "Note that each cluster represents a narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:45.702879Z",
     "iopub.status.busy": "2021-05-19T06:53:45.701861Z",
     "iopub.status.idle": "2021-05-19T06:53:45.705996Z",
     "shell.execute_reply": "2021-05-19T06:53:45.706475Z"
    },
    "papermill": {
     "duration": 0.060843,
     "end_time": "2021-05-19T06:53:45.706639",
     "exception": false,
     "start_time": "2021-05-19T06:53:45.645796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets_to_consider = 'fully_cleaned_tweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:45.815078Z",
     "iopub.status.busy": "2021-05-19T06:53:45.814066Z",
     "iopub.status.idle": "2021-05-19T06:53:45.822167Z",
     "shell.execute_reply": "2021-05-19T06:53:45.821213Z"
    },
    "papermill": {
     "duration": 0.063435,
     "end_time": "2021-05-19T06:53:45.822337",
     "exception": false,
     "start_time": "2021-05-19T06:53:45.758902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "final_clusters= np.unique(dfUnique['cl_num'])\n",
    "print(final_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:45.936310Z",
     "iopub.status.busy": "2021-05-19T06:53:45.935548Z",
     "iopub.status.idle": "2021-05-19T06:53:45.956764Z",
     "shell.execute_reply": "2021-05-19T06:53:45.957305Z"
    },
    "papermill": {
     "duration": 0.079326,
     "end_time": "2021-05-19T06:53:45.957448",
     "exception": false,
     "start_time": "2021-05-19T06:53:45.878122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store all tweets corrsponding to each cluster in a file\n",
    "for i in final_clusters:\n",
    "    with open('./tweets_Cluster_'+str(i)+'.txt','w') as out:\n",
    "        y=''\n",
    "        for x in dfUnique[tweets_to_consider][dfUnique.cl_num==i]:\n",
    "            y=y+x+'. '\n",
    "        out.write(y)\n",
    "        out.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:46.071408Z",
     "iopub.status.busy": "2021-05-19T06:53:46.070739Z",
     "iopub.status.idle": "2021-05-19T06:53:56.005950Z",
     "shell.execute_reply": "2021-05-19T06:53:56.005363Z"
    },
    "papermill": {
     "duration": 9.993244,
     "end_time": "2021-05-19T06:53:56.006070",
     "exception": false,
     "start_time": "2021-05-19T06:53:46.012826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              extracted_phrases  cluster_num\n",
      "0                    brexit are          0.0\n",
      "1                        people          0.0\n",
      "2                    see people          0.0\n",
      "3                          govt          0.0\n",
      "4                    govt wants          0.0\n",
      "...                         ...          ...\n",
      "9617  positive impact long term         11.0\n",
      "9618            economic impact         11.0\n",
      "9619      impact demonetization         11.0\n",
      "9620                 shops have         11.0\n",
      "9621       showrooms shops have         11.0\n",
      "\n",
      "[9622 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#A combination of (Noun, adjective, cardinal number, foreign word and Verb) are being extracted now\n",
    "#Extract chunks matching pattern. Patterns are:\n",
    "#1) Noun phrase (2 or more nouns occurring together. Ex United states of America, Abdul Kalam etc)\n",
    "#2) Number followed by Noun (Ex: 28 Terrorists, 45th President)\n",
    "#3) Adjective followed by Noun (Ex: Economic impact, beautiful inauguration)\n",
    "#4) Foreign word (Ex: Jallikattu, Narendra modi, Pappu)\n",
    "#5) Noun followed by Verb (Ex: Terrorists arrested)\n",
    "#And a combination of all 5\n",
    "        \n",
    "import re\n",
    "import nltk\n",
    "\n",
    "phrases = pd.DataFrame({'extracted_phrases': [], 'cluster_num': []})\n",
    "\n",
    "\n",
    "A = '(CD|JJ)/\\w+\\s'  #cd or jj\n",
    "B = '(NN|NNS|NNP|NNPS)/\\w+\\s'  #nouns\n",
    "C = '(VB|VBD|VBG|VBN|VBP|VBZ)/\\w+\\s' #verbs\n",
    "D = 'FW/\\w+\\s'  #foreign word\n",
    "patterns = ['('+A+B+')+', '('+D+B+')+','('+D+')+', '('+B+')+', '('+D+A+B+')+', \n",
    "           '('+B+C+')+', '('+D+B+C+')+', '('+B+A+B+')+', '('+B+B+C+')+'] \n",
    "\n",
    "\n",
    "def extract_phrases(tag1, tag2, sentences):\n",
    "    extract_phrase = []\n",
    "    for sentence in sentences:\n",
    "        phrase = []\n",
    "        next_word = 0\n",
    "        for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "            if next_word == 1:\n",
    "                next_word = 0\n",
    "                if pos == tag2:\n",
    "                    extract_phrase = np.append(extract_phrase,phrase + ' ' + word) \n",
    "            \n",
    "            if pos == tag1:\n",
    "                next_word = 1\n",
    "                phrase = word\n",
    "    return extract_phrase\n",
    "\n",
    "for i in cluster_name:\n",
    "    File = open('./tweets_Cluster_'+str(i)+'.txt', 'r') #open file\n",
    "    lines = File.read() #read all lines\n",
    "    sentences = nltk.sent_tokenize(lines) #tokenize sentences\n",
    "\n",
    "    for sentence in sentences: \n",
    "        f = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "        tag_seq = []\n",
    "        for word, pos in f:\n",
    "            tag_seq.append(pos+'/'+ word)\n",
    "        X = \" \".join(tag_seq)\n",
    "\n",
    "        phrase = []\n",
    "        for j in range(len(patterns)):\n",
    "            if re.search(patterns[j], X):\n",
    "                phrase.append(' '.join([word.split('/')[1] for word in re.search(patterns[j], X).group(0).split()]))\n",
    "    \n",
    "        k = pd.DataFrame({'extracted_phrases': np.unique(phrase), 'cluster_num': int(i)})\n",
    "    \n",
    "        phrases = pd.concat([phrases,k], ignore_index = True)\n",
    "\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053388,
     "end_time": "2021-05-19T06:53:56.112852",
     "exception": false,
     "start_time": "2021-05-19T06:53:56.059464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Keeping the largest phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:56.310107Z",
     "iopub.status.busy": "2021-05-19T06:53:56.230857Z",
     "iopub.status.idle": "2021-05-19T06:53:58.147232Z",
     "shell.execute_reply": "2021-05-19T06:53:58.146665Z"
    },
    "papermill": {
     "duration": 1.981493,
     "end_time": "2021-05-19T06:53:58.147342",
     "exception": false,
     "start_time": "2021-05-19T06:53:56.165849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For each phrase identified replace all the substrings by the largest phrase \n",
    "#Ex: lakh looted,40 lakh looted and Rs 40 lakh looted, replace all by single largest phrase - Rs 40 lakh looted \n",
    "#i.e. instead of 3 different phrases, there will be only one large phrase\n",
    "\n",
    "phrases_final = pd.DataFrame({'extracted_phrases': [], 'cluster_num': []})\n",
    "for i in cluster_name:\n",
    "    phrases_for_each_cluster = []\n",
    "    cluster_phrases = phrases['extracted_phrases'][phrases.cluster_num == i]\n",
    "    cluster_phrases = np.unique(np.array(cluster_phrases))\n",
    "    for j in range(len(cluster_phrases)):\n",
    "        \n",
    "        phrase = cluster_phrases[j]\n",
    "        updated_cluster_phrases = np.delete((cluster_phrases), j)\n",
    "        if any(phrase in phr for phr in updated_cluster_phrases): \n",
    "            'y'\n",
    "        else: \n",
    "            #considering phrases of length greater than 1 only\n",
    "            if (len(phrase.split(' '))) > 1:\n",
    "                phrases_for_each_cluster.append(phrase)\n",
    "    k = pd.DataFrame({'extracted_phrases': phrases_for_each_cluster, 'cluster_num': int(i) })\n",
    "    \n",
    "    phrases_final = pd.concat([phrases_final,k], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:58.257566Z",
     "iopub.status.busy": "2021-05-19T06:53:58.256961Z",
     "iopub.status.idle": "2021-05-19T06:53:58.269822Z",
     "shell.execute_reply": "2021-05-19T06:53:58.269109Z"
    },
    "papermill": {
     "duration": 0.06912,
     "end_time": "2021-05-19T06:53:58.269938",
     "exception": false,
     "start_time": "2021-05-19T06:53:58.200818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_phrases</th>\n",
       "      <th>cluster_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 indians</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 request</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 currencies</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 sneezes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 rupee</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>smita dutta</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>srinagartimes fresh currency</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>supports note</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>taxmannindia demonetization</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>waste time come</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4452 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 extracted_phrases  cluster_num\n",
       "0                        1 indians          0.0\n",
       "1                        1 request          0.0\n",
       "2                    10 currencies          0.0\n",
       "3                       10 sneezes          0.0\n",
       "4                        100 rupee          0.0\n",
       "...                            ...          ...\n",
       "4447                   smita dutta         11.0\n",
       "4448  srinagartimes fresh currency         11.0\n",
       "4449                 supports note         11.0\n",
       "4450   taxmannindia demonetization         11.0\n",
       "4451               waste time come         11.0\n",
       "\n",
       "[4452 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056763,
     "end_time": "2021-05-19T06:53:58.380853",
     "exception": false,
     "start_time": "2021-05-19T06:53:58.324090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### For each phrase in each cluster, calculate term frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:53:58.511303Z",
     "iopub.status.busy": "2021-05-19T06:53:58.510577Z",
     "iopub.status.idle": "2021-05-19T06:54:31.761121Z",
     "shell.execute_reply": "2021-05-19T06:54:31.760375Z"
    },
    "papermill": {
     "duration": 33.325775,
     "end_time": "2021-05-19T06:54:31.761234",
     "exception": false,
     "start_time": "2021-05-19T06:53:58.435459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Term-frequency : For each cluster, calculate the number of times a given phrase occur in the tweets of that cluster\n",
    "\n",
    "phrases_final['term_freq'] = len(phrases_final)*[0]\n",
    "\n",
    "for i in cluster_name:\n",
    "    for phrase in phrases_final['extracted_phrases'][phrases_final.cluster_num == i]:\n",
    "        tweets = dfUnique[tweets_to_consider][dfUnique.cl_num == i]\n",
    "        for tweet in tweets:\n",
    "            if phrase in tweet:\n",
    "                phrases_final['term_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num == i)] = phrases_final['term_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num == i)] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:54:31.884629Z",
     "iopub.status.busy": "2021-05-19T06:54:31.883695Z",
     "iopub.status.idle": "2021-05-19T06:54:31.888467Z",
     "shell.execute_reply": "2021-05-19T06:54:31.887848Z"
    },
    "papermill": {
     "duration": 0.072353,
     "end_time": "2021-05-19T06:54:31.888575",
     "exception": false,
     "start_time": "2021-05-19T06:54:31.816222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_phrases</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>term_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 indians</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 request</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 currencies</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 sneezes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 rupee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>smita dutta</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>srinagartimes fresh currency</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>supports note</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>taxmannindia demonetization</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>waste time come</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4452 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 extracted_phrases  cluster_num  term_freq\n",
       "0                        1 indians          0.0          1\n",
       "1                        1 request          0.0          1\n",
       "2                    10 currencies          0.0          1\n",
       "3                       10 sneezes          0.0          2\n",
       "4                        100 rupee          0.0          2\n",
       "...                            ...          ...        ...\n",
       "4447                   smita dutta         11.0          1\n",
       "4448  srinagartimes fresh currency         11.0          1\n",
       "4449                 supports note         11.0          2\n",
       "4450   taxmannindia demonetization         11.0          1\n",
       "4451               waste time come         11.0          2\n",
       "\n",
       "[4452 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:54:32.040376Z",
     "iopub.status.busy": "2021-05-19T06:54:32.021044Z",
     "iopub.status.idle": "2021-05-19T06:55:51.856352Z",
     "shell.execute_reply": "2021-05-19T06:55:51.855526Z"
    },
    "papermill": {
     "duration": 79.912367,
     "end_time": "2021-05-19T06:55:51.856490",
     "exception": false,
     "start_time": "2021-05-19T06:54:31.944123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#Document-frequency\n",
    "phrases_final['doc_freq'] = len(phrases_final)*[0]\n",
    "\n",
    "\n",
    "# for each phrase, compute the number of clusters that Sphrase occurs in\n",
    "for phrase in phrases_final['extracted_phrases']:\n",
    "    for i in cluster_name:\n",
    "        all_tweets = ''\n",
    "        for tweet in dfUnique[tweets_to_consider][dfUnique.cl_num == i]:\n",
    "            all_tweets = all_tweets + tweet + '. ' \n",
    "        if phrase in all_tweets:\n",
    "            phrases_final['doc_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num == i)] = phrases_final['doc_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num == i)] + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:51.979606Z",
     "iopub.status.busy": "2021-05-19T06:55:51.978574Z",
     "iopub.status.idle": "2021-05-19T06:55:51.981565Z",
     "shell.execute_reply": "2021-05-19T06:55:51.980963Z"
    },
    "papermill": {
     "duration": 0.067946,
     "end_time": "2021-05-19T06:55:51.981704",
     "exception": false,
     "start_time": "2021-05-19T06:55:51.913758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "phrases_final['doc_freq'] = phrases_final['doc_freq'].apply(lambda x: math.log10(n_best_clusters/(x)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055286,
     "end_time": "2021-05-19T06:55:52.092822",
     "exception": false,
     "start_time": "2021-05-19T06:55:52.037536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### For each phrase in each cluster, calculate tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:52.211270Z",
     "iopub.status.busy": "2021-05-19T06:55:52.210644Z",
     "iopub.status.idle": "2021-05-19T06:55:52.214278Z",
     "shell.execute_reply": "2021-05-19T06:55:52.213251Z"
    },
    "papermill": {
     "duration": 0.06522,
     "end_time": "2021-05-19T06:55:52.214401",
     "exception": false,
     "start_time": "2021-05-19T06:55:52.149181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phrases_final['tf-idf'] = phrases_final['term_freq']*phrases_final['doc_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:52.345018Z",
     "iopub.status.busy": "2021-05-19T06:55:52.343931Z",
     "iopub.status.idle": "2021-05-19T06:55:52.348703Z",
     "shell.execute_reply": "2021-05-19T06:55:52.348055Z"
    },
    "papermill": {
     "duration": 0.077854,
     "end_time": "2021-05-19T06:55:52.348816",
     "exception": false,
     "start_time": "2021-05-19T06:55:52.270962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_phrases</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 indians</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.079181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 request</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.079181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 currencies</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.079181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 sneezes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>2.158362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 rupee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>2.158362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>smita dutta</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.079181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>srinagartimes fresh currency</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.079181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>supports note</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>2.158362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>taxmannindia demonetization</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.079181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>waste time come</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>2.158362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4452 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 extracted_phrases  cluster_num  term_freq  doc_freq    tf-idf\n",
       "0                        1 indians          0.0          1  1.079181  1.079181\n",
       "1                        1 request          0.0          1  1.079181  1.079181\n",
       "2                    10 currencies          0.0          1  1.079181  1.079181\n",
       "3                       10 sneezes          0.0          2  1.079181  2.158362\n",
       "4                        100 rupee          0.0          2  1.079181  2.158362\n",
       "...                            ...          ...        ...       ...       ...\n",
       "4447                   smita dutta         11.0          1  1.079181  1.079181\n",
       "4448  srinagartimes fresh currency         11.0          1  1.079181  1.079181\n",
       "4449                 supports note         11.0          2  1.079181  2.158362\n",
       "4450   taxmannindia demonetization         11.0          1  1.079181  1.079181\n",
       "4451               waste time come         11.0          2  1.079181  2.158362\n",
       "\n",
       "[4452 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056997,
     "end_time": "2021-05-19T06:55:52.463775",
     "exception": false,
     "start_time": "2021-05-19T06:55:52.406778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### For each cluster find top few phrases and respective sentiment\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:52.594231Z",
     "iopub.status.busy": "2021-05-19T06:55:52.593375Z",
     "iopub.status.idle": "2021-05-19T06:55:52.720742Z",
     "shell.execute_reply": "2021-05-19T06:55:52.721293Z"
    },
    "papermill": {
     "duration": 0.2012,
     "end_time": "2021-05-19T06:55:52.721457",
     "exception": false,
     "start_time": "2021-05-19T06:55:52.520257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "phrases_final['diff_tf-idf'] = len(phrases_final)*[0]\n",
    "\n",
    "narrative = pd.DataFrame({'cl_num': [], 'abstraction': []})\n",
    "for i in cluster_name: \n",
    "    # arrange in descending order of tf-idf score\n",
    "    phrases_final = phrases_final.sort_values(['cluster_num','tf-idf'], ascending=[1,0])\n",
    "    \n",
    "    #Break this distribution at a point where the difference between any consecutive phrases is maximum\n",
    "    #difference between consecutive values of tf-idf \n",
    "    phrases_final['diff_tf-idf'][phrases_final.cluster_num == i] = abs(phrases_final['tf-idf'][phrases_final.cluster_num == i] - phrases_final['tf-idf'][phrases_final.cluster_num == i].shift(1))\n",
    "\n",
    "    #The last value for each cluster will be 'NaN'. Replacing it with '0'. \n",
    "    phrases_final = phrases_final.fillna(0)\n",
    "    \n",
    "    phrases_final = phrases_final.reset_index(drop = True) #to avoid old index being added as a new column\n",
    "    if len(phrases_final[phrases_final.cluster_num == i]) != 0:\n",
    "        \n",
    "        #index corresponding to the highest difference\n",
    " \n",
    "        ind = (phrases_final['diff_tf-idf'][phrases_final.cluster_num == i]).idxmax()\n",
    "        \n",
    "        abstract = phrases_final['extracted_phrases'][:ind+1][phrases_final.cluster_num == i]\n",
    "    \n",
    "    \n",
    "        #store the abstraction corresponding to each cluster\n",
    "        k = pd.DataFrame({'cl_num': int(i), 'abstraction': abstract})\n",
    "        narrative = pd.concat([narrative,k], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:52.861019Z",
     "iopub.status.busy": "2021-05-19T06:55:52.860308Z",
     "iopub.status.idle": "2021-05-19T06:55:52.864998Z",
     "shell.execute_reply": "2021-05-19T06:55:52.865472Z"
    },
    "papermill": {
     "duration": 0.086307,
     "end_time": "2021-05-19T06:55:52.865637",
     "exception": false,
     "start_time": "2021-05-19T06:55:52.779330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>cl_num</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>It's amusing to see people who have elected Tr...</td>\n",
       "      <td>its amusing  see people who have elected trump...</td>\n",
       "      <td>its amusing see people who have elected trump ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[its, amusing, see, people, who, have, elected...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>#NetasCASHIn Govt wants debate over #DeMonetiz...</td>\n",
       "      <td>netascashin govt wants debate over  demonetiz...</td>\n",
       "      <td>netascashin govt wants debate over demonetizat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[netascashin, govt, wants, debate, over, demon...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>#NetasCASHIn Govt wants debate over #DeMonetiz...</td>\n",
       "      <td>netascashin govt wants debate over  demonetiz...</td>\n",
       "      <td>netascashin govt wants debate over demonetizat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[netascashin, govt, wants, debate, over, demon...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>New Delhi: @AamAadmiParty demonstration agains...</td>\n",
       "      <td>new delhi   aamaadmiparty demonstration agains...</td>\n",
       "      <td>new delhi aamaadmiparty demonstration against ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[new, delhi, aamaadmiparty, demonstration, aga...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>New Delhi: Opposition leaders demonstration ag...</td>\n",
       "      <td>new delhi  opposition leaders demonstration ag...</td>\n",
       "      <td>new delhi opposition leaders demonstration aga...</td>\n",
       "      <td>1</td>\n",
       "      <td>[new, delhi, opposition, leaders, demonstratio...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>RT @AshwinderRaj: \"Impact of Demonetization on...</td>\n",
       "      <td>ashwinderraj  impact  demonetization  resident...</td>\n",
       "      <td>ashwinderraj impact demonetization residential...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ashwinderraj, impact, demonetization, residen...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>RT @DipendraDipzo: #Demonetization effect \\r\\n...</td>\n",
       "      <td>dipendradipzo   demonetization effect  here co...</td>\n",
       "      <td>dipendradipzo demonetization effect here comes...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dipendradipzo, demonetization, effect, here, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>@Vernaculis This crap will just keep getting p...</td>\n",
       "      <td>this crap will just keep getting pushed more ...</td>\n",
       "      <td>this crap will just keep getting pushed more a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[this, crap, will, just, keep, getting, pushed...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>Note ban will have positive impact in long ter...</td>\n",
       "      <td>note ban will have positive impact  long term ...</td>\n",
       "      <td>note ban will have positive impact long term w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[note, ban, will, have, positive, impact, long...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Economic impact of #demonetization : Smaller S...</td>\n",
       "      <td>economic impact   demonetization   smaller sho...</td>\n",
       "      <td>economic impact demonetization smaller showroo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[economic, impact, demonetization, smaller, sh...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3157 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "1623  It's amusing to see people who have elected Tr...   \n",
       "275   #NetasCASHIn Govt wants debate over #DeMonetiz...   \n",
       "276   #NetasCASHIn Govt wants debate over #DeMonetiz...   \n",
       "1752  New Delhi: @AamAadmiParty demonstration agains...   \n",
       "1753  New Delhi: Opposition leaders demonstration ag...   \n",
       "...                                                 ...   \n",
       "1936  RT @AshwinderRaj: \"Impact of Demonetization on...   \n",
       "2019  RT @DipendraDipzo: #Demonetization effect \\r\\n...   \n",
       "753   @Vernaculis This crap will just keep getting p...   \n",
       "1773  Note ban will have positive impact in long ter...   \n",
       "1311  Economic impact of #demonetization : Smaller S...   \n",
       "\n",
       "                                          cleaned_tweet  \\\n",
       "1623  its amusing  see people who have elected trump...   \n",
       "275    netascashin govt wants debate over  demonetiz...   \n",
       "276    netascashin govt wants debate over  demonetiz...   \n",
       "1752  new delhi   aamaadmiparty demonstration agains...   \n",
       "1753  new delhi  opposition leaders demonstration ag...   \n",
       "...                                                 ...   \n",
       "1936  ashwinderraj  impact  demonetization  resident...   \n",
       "2019  dipendradipzo   demonetization effect  here co...   \n",
       "753    this crap will just keep getting pushed more ...   \n",
       "1773  note ban will have positive impact  long term ...   \n",
       "1311  economic impact   demonetization   smaller sho...   \n",
       "\n",
       "                                    fully_cleaned_tweet  sentiment  \\\n",
       "1623  its amusing see people who have elected trump ...          1   \n",
       "275   netascashin govt wants debate over demonetizat...          1   \n",
       "276   netascashin govt wants debate over demonetizat...          1   \n",
       "1752  new delhi aamaadmiparty demonstration against ...          1   \n",
       "1753  new delhi opposition leaders demonstration aga...          1   \n",
       "...                                                 ...        ...   \n",
       "1936  ashwinderraj impact demonetization residential...          1   \n",
       "2019  dipendradipzo demonetization effect here comes...          1   \n",
       "753   this crap will just keep getting pushed more a...          1   \n",
       "1773  note ban will have positive impact long term w...          1   \n",
       "1311  economic impact demonetization smaller showroo...          1   \n",
       "\n",
       "                                        tokenized_tweet  cl_num  freq  \n",
       "1623  [its, amusing, see, people, who, have, elected...       0     1  \n",
       "275   [netascashin, govt, wants, debate, over, demon...       0     1  \n",
       "276   [netascashin, govt, wants, debate, over, demon...       0     1  \n",
       "1752  [new, delhi, aamaadmiparty, demonstration, aga...       0     1  \n",
       "1753  [new, delhi, opposition, leaders, demonstratio...       0     1  \n",
       "...                                                 ...     ...   ...  \n",
       "1936  [ashwinderraj, impact, demonetization, residen...      11     1  \n",
       "2019  [dipendradipzo, demonetization, effect, here, ...      11    40  \n",
       "753   [this, crap, will, just, keep, getting, pushed...      11     1  \n",
       "1773  [note, ban, will, have, positive, impact, long...      11     1  \n",
       "1311  [economic, impact, demonetization, smaller, sh...      11     1  \n",
       "\n",
       "[3157 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUnique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:52.989925Z",
     "iopub.status.busy": "2021-05-19T06:55:52.989219Z",
     "iopub.status.idle": "2021-05-19T06:55:53.000995Z",
     "shell.execute_reply": "2021-05-19T06:55:53.001512Z"
    },
    "papermill": {
     "duration": 0.077589,
     "end_time": "2021-05-19T06:55:53.001698",
     "exception": false,
     "start_time": "2021-05-19T06:55:52.924109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Assigning polarity based on the sentiment for each tweet 2=negative, 1=positive, 3=neutral\n",
    "dfUnique['polarity'] = np.NaN\n",
    "dfUnique['polarity'][dfUnique.sentiment == 0.5] = \"3\"\n",
    "dfUnique['polarity'][dfUnique.sentiment == 1] = \"1\"\n",
    "dfUnique['polarity'][dfUnique.sentiment == 0] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059266,
     "end_time": "2021-05-19T06:55:53.119830",
     "exception": false,
     "start_time": "2021-05-19T06:55:53.060564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Assign the sentiment to each extracted phrases\n",
    "count the number of tweets, a phrase has occurred in positive, negative and neutral context. Assign the most occurred sentiment to the phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:53.258504Z",
     "iopub.status.busy": "2021-05-19T06:55:53.257401Z",
     "iopub.status.idle": "2021-05-19T06:55:53.388384Z",
     "shell.execute_reply": "2021-05-19T06:55:53.387626Z"
    },
    "papermill": {
     "duration": 0.210084,
     "end_time": "2021-05-19T06:55:53.388501",
     "exception": false,
     "start_time": "2021-05-19T06:55:53.178417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#find the highest occurring sentiment corresponding to each tweet\n",
    "def find_mode(a):\n",
    "    b = Counter(a).most_common(3)\n",
    "    mode = []; c_max = 0\n",
    "    for a,c in b:\n",
    "        if c>c_max:\n",
    "            c_max = c\n",
    "        if c_max == c:\n",
    "            mode.append(a)  \n",
    "    print(mode)\n",
    "    mode.sort()\n",
    "    print(mode)\n",
    "    \n",
    "    ## if mode is 3&2 i.e. neutral and negative, assign the overall sentiment for that phrase as negative, \n",
    "    ## if mode is 3&1 i.e. neutral and positive, assign the overall sentiment for that phrase as positive,\n",
    "    ## if mode is 2&1 i.e. negative and positive, assign the overall sentiment for that phrase as neutal, \n",
    "    ## if mode is 3&2&1 i.e. negative, positive and neutral, assign the overall sentiment for that phrase as neutral\n",
    "    \n",
    "    if len(mode) == 1:\n",
    "        return mode[0]\n",
    "    \n",
    "    elif (len(mode) == 2) & (mode[1]=='3'):\n",
    "        return mode[0]\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "#1=>+ve 2=>-ve 3=>Neutral\n",
    "narrative['expression'] = -1\n",
    "dfUnique = dfUnique.reset_index(drop = True)\n",
    "for i in cluster_name:\n",
    "    tweets = dfUnique[tweets_to_consider][dfUnique.cl_num == i]\n",
    "    abstracts = narrative['abstraction'][narrative.cl_num == i] \n",
    "    for abst in abstracts:\n",
    "        sent = []\n",
    "        for tweet, polarity in zip(dfUnique[tweets_to_consider][dfUnique.cl_num == i], dfUnique['polarity'][dfUnique.cl_num == i]):\n",
    "            if abst in tweet:\n",
    "                sent = np.append(sent, polarity)\n",
    "        \n",
    "        \n",
    "        if len(sent)!=0:\n",
    "            ## if mode is 3&2-2, 3&1-1, 2&1-3, 3&2&1 - 3\n",
    "            senti = find_mode(sent)\n",
    "            if senti == '2':\n",
    "                sent_value = \"Negative\"\n",
    "            elif senti == '1':\n",
    "                sent_value = \"Positive\"\n",
    "            else:\n",
    "                sent_value = \"Neutral\"\n",
    "            narrative['expression'][(narrative.abstraction == abst) & (narrative.cl_num == i)] = sent_value\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059671,
     "end_time": "2021-05-19T06:55:53.509397",
     "exception": false,
     "start_time": "2021-05-19T06:55:53.449726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# Save the narratives in excel file\n",
    " With each sheet in the file representing 1 narrative ( == 1 cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:53.642989Z",
     "iopub.status.busy": "2021-05-19T06:55:53.642008Z",
     "iopub.status.idle": "2021-05-19T06:55:54.299518Z",
     "shell.execute_reply": "2021-05-19T06:55:54.298819Z"
    },
    "papermill": {
     "duration": 0.730232,
     "end_time": "2021-05-19T06:55:54.299681",
     "exception": false,
     "start_time": "2021-05-19T06:55:53.569449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sudo pip install xlwt\n",
    "#sudo pip3 install openpyxl\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "#Save the narratives in an excel file \n",
    "\n",
    "writer = pd.ExcelWriter('narrative.xlsx')\n",
    "for i in cluster_name:\n",
    "    df1 = pd.DataFrame(dfUnique[['tweet','freq']][dfUnique.cl_num == i]).sort_values(['freq'], ascending = [0])\n",
    "    df1 = pd.DataFrame({'tweet': dfUnique['tweet'][dfUnique.cl_num == i], 'freq': dfUnique['freq'][dfUnique.cl_num == i]}) \n",
    "    df1 = df1.sort_values(['freq'], ascending = [0]) \n",
    "\n",
    "    df2 = pd.DataFrame({ 'abstraction': narrative['abstraction'][narrative.cl_num == i], 'expression': narrative['expression'][narrative.cl_num == i]})\n",
    "    df3 = pd.DataFrame({'abstraction': (len(df1)-len(df2))*['-'], 'expression': (len(df1)-len(df2))*['-']})\n",
    "    df2 = df2.append(df3)\n",
    "\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    df1['abstraction'] = df2['abstraction']\n",
    "    df1['expression'] = df2['expression']\n",
    "\n",
    "    df1.to_excel(writer,'narrative_cluster'+str(i))\n",
    "\n",
    "writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T06:55:54.436873Z",
     "iopub.status.busy": "2021-05-19T06:55:54.435906Z",
     "iopub.status.idle": "2021-05-19T06:55:54.441574Z",
     "shell.execute_reply": "2021-05-19T06:55:54.441054Z"
    },
    "papermill": {
     "duration": 0.082221,
     "end_time": "2021-05-19T06:55:54.441711",
     "exception": false,
     "start_time": "2021-05-19T06:55:54.359490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl_num</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>people have</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>amul milk</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>demonetization issue</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>flawless kick</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>mannkibaat jankibaat</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>hear navkendar</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6 months</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>aap join</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>govt explains</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>samajwadi partys jaya bachchan</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>benefit demonetization</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>shop owner gets</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>40 lakh</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>common man</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>politics nitishkumar supports</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>coop banks</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.0</td>\n",
       "      <td>system india article</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.0</td>\n",
       "      <td>overall impact</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>demonetization dea secy dasshaktikanta</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.0</td>\n",
       "      <td>modi had</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.0</td>\n",
       "      <td>announcement ncbn sold</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.0</td>\n",
       "      <td>nation 8086 people</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.0</td>\n",
       "      <td>prof vaidyanathan</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.0</td>\n",
       "      <td>time has</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.0</td>\n",
       "      <td>views demonetization</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.0</td>\n",
       "      <td>modibharosa huge support</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.0</td>\n",
       "      <td>app shared</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.0</td>\n",
       "      <td>youtube video</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.0</td>\n",
       "      <td>question was paytm informed</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.0</td>\n",
       "      <td>govts innovative solution</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.0</td>\n",
       "      <td>help farmers affected</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.0</td>\n",
       "      <td>backs demonetization says</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cl_num                             abstraction expression\n",
       "0      0.0                             people have   Positive\n",
       "1      0.0                               amul milk   Positive\n",
       "2      1.0                    demonetization issue   Negative\n",
       "3      1.0                           flawless kick   Negative\n",
       "4      1.0                    mannkibaat jankibaat   Negative\n",
       "5      1.0                          hear navkendar   Negative\n",
       "6      2.0                                6 months   Negative\n",
       "7      2.0                                aap join   Negative\n",
       "8      2.0                           govt explains   Negative\n",
       "9      2.0          samajwadi partys jaya bachchan   Negative\n",
       "10     2.0                  benefit demonetization   Negative\n",
       "11     3.0                         shop owner gets   Negative\n",
       "12     3.0                                 40 lakh   Negative\n",
       "13     5.0                              common man   Negative\n",
       "14     5.0           politics nitishkumar supports   Negative\n",
       "15     5.0                              coop banks   Negative\n",
       "16     6.0                    system india article   Negative\n",
       "17     6.0                          overall impact   Negative\n",
       "18     6.0  demonetization dea secy dasshaktikanta   Negative\n",
       "19     7.0                                modi had   Positive\n",
       "20     7.0                  announcement ncbn sold   Positive\n",
       "21     9.0                      nation 8086 people   Positive\n",
       "22     9.0                       prof vaidyanathan   Positive\n",
       "23     9.0                                time has   Positive\n",
       "24     9.0                    views demonetization   Positive\n",
       "25     9.0                modibharosa huge support   Positive\n",
       "26     9.0                              app shared   Positive\n",
       "27    10.0                           youtube video   Positive\n",
       "28    10.0             question was paytm informed   Positive\n",
       "29    11.0               govts innovative solution   Positive\n",
       "30    11.0                   help farmers affected   Positive\n",
       "31    11.0               backs demonetization says   Positive"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060281,
     "end_time": "2021-05-19T06:55:54.563632",
     "exception": false,
     "start_time": "2021-05-19T06:55:54.503351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:#ff6666' role=\"tab\" aria-controls=\"home\"><center>Thank You 🙏 </center></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.060265,
     "end_time": "2021-05-19T06:55:54.684669",
     "exception": false,
     "start_time": "2021-05-19T06:55:54.624404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 292.604677,
   "end_time": "2021-05-19T06:55:54.854814",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-19T06:51:02.250137",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
